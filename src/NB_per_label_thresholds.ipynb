{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file should be used from the root of the repository\n",
    "import pyeddl.eddl as eddl\n",
    "import pyecvl.ecvl as ecvl\n",
    "from pyeddl.tensor import Tensor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from posixpath import join\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from utils.data_partitioning import load_data_split\n",
    "from eddl_lib.uc5_dataset import Uc5Dataset\n",
    "\n",
    "# paths\n",
    "exp_fld = \"/mnt/datasets/uc5/UC5_pipeline_forked/experiments_eddl/wp6\"\n",
    "cnn_fn = \"cnn_84val_neptune179.onnx\"\n",
    "ds_fn = \"img_reports_phi2_enc.tsv\"\n",
    "img_fld = \"/mnt/datasets/uc5/std-dataset/image\"\n",
    "\n",
    "# read files from exp_fld\n",
    "train_ids, valid_ids, test_ids = load_data_split(exp_fld)\n",
    "\n",
    "cnn = eddl.import_net_from_onnx_file(join(exp_fld, cnn_fn))\n",
    "eddl.build(\n",
    "    cnn,\n",
    "    eddl.rmsprop(0.01),\n",
    "    [\"soft_cross_entropy\"],\n",
    "    [\"categorical_accuracy\"],\n",
    "    eddl.CS_GPU(mem=\"full_mem\"),  # if args.gpu else eddl.CS_CPU(mem=args.mem),\n",
    "    False  # do not initialize weights to random values\n",
    ")\n",
    "cnn.resize(1)\n",
    "# eddl.summary(cnn)\n",
    "eddl.set_mode(cnn, 0)\n",
    "\n",
    "ds = pd.read_csv(join(exp_fld, ds_fn), sep=\"\\t\").set_index(\"filename\")  # .set_index(\"image_filename\")\n",
    "print(ds.shape)\n",
    "print(ds.head())\n",
    "\n",
    "semantic_dim = eddl.getLayer(cnn, \"cnn_out\").output.shape[1]\n",
    "print(\"semantic dimension:\", semantic_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux functions\n",
    "def load_image(filename):\n",
    "    augs = ecvl.SequentialAugmentationContainer([\n",
    "                ecvl.AugToFloat32(divisor=255.0),\n",
    "                ecvl.AugNormalize([0.48197903, 0.48197903, 0.48197903], [0.26261734, 0.26261734, 0.26261734]),\n",
    "                ecvl.AugResizeDim([300, 300]),\n",
    "                ecvl.AugCenterCrop([224, 224]),  # to do: test random crop also in prediction\n",
    "                ])\n",
    "    img = ecvl.ImRead(filename, flags=None)  # , flags=ecvl.ImReadMode.GRAYSCALE)\n",
    "    ecvl.RearrangeChannels(img, img, \"xyc\")\n",
    "    augs.Apply(img)\n",
    "    ecvl.RearrangeChannels(img, img, \"cxy\")\n",
    "    return img\n",
    "\n",
    "def label_list(lab_str):\n",
    "    return [int(s) for s in lab_str.split(\";\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ids = test_ids\n",
    "\n",
    "predictions = np.empty( (semantic_dim, len(split_ids)) )\n",
    "targets = np.empty_like(predictions)\n",
    "predictions.fill(np.nan)\n",
    "targets.fill(np.nan)\n",
    "\n",
    "for pos, id in enumerate(split_ids):\n",
    "    if (pos % 100) == 0:\n",
    "        print(\".\", end=\"\")\n",
    "    img = load_image(join(img_fld, id))\n",
    "    # img = ecvl.ImageToTensor(img)\n",
    "    a = np.expand_dims(np.array(img, copy=False), axis=0)  # add batch dimension\n",
    "    eddl.forward(cnn, [Tensor.fromarray(a)])\n",
    "\n",
    "    layer = eddl.getLayer(cnn, \"cnn_out\")\n",
    "    p = np.array(eddl.getOutput(layer), copy=False)\n",
    "    predictions[:, pos] = p\n",
    "    \n",
    "    labels = np.zeros_like(p)\n",
    "    for l in label_list(ds.loc[id].labels):\n",
    "        labels[0, l] = 1    \n",
    "    targets[:, pos] = labels\n",
    "    # print(labels)\n",
    "    # if pos == 50:\n",
    "    #     print(\"dev mode, breaking at 50\")\n",
    "    #     break\n",
    "    #print(p.shape)\n",
    "    # cnn_out_in = eddl.Input([semantic_dim], name=\"in_semantic_features\")\n",
    "# for i, split in enumerate([train_ids, valid_ids, test_ids]):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "sel_thresholds = np.zeros((predictions.shape[0]),)\n",
    "for i in range(predictions.shape[0]):\n",
    "    y_est = predictions[i, :]\n",
    "    y = targets[i, :]\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_est)\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    m2 = gmeans[np.argmax(gmeans)]\n",
    "    \n",
    "    y_est1 = np.where(y_est > m2, 1, 0)\n",
    "    print(\"***\")\n",
    "    print(f\"label {i}, with auc:\", accuracy_score(y_est1, y)*100)\n",
    "    y_est2 = np.where(y_est > 0.5, 1, 0)\n",
    "    print(f\"label {i}, acc:\", accuracy_score(y_est2, y)*100)\n",
    "    y_est3 = np.where(y_est > 0, 1, 0)\n",
    "    print(f\"label {i}, with 0:\", accuracy_score(y_est3, y)*100)\n",
    "    # plt.scatter(range(len(y_est)), y_est, s = 1)\n",
    "    \n",
    "    # print(fpr)\n",
    "    # #  Youdenâ€™s J statistic\n",
    "    J = tpr - fpr\n",
    "    m = np.argmax(J)\n",
    "    sel_thresholds[i] = m2\n",
    "    # print(f\"label {i}, threshold: {thresholds[-1]:.2f}, gmeans: {m2:.2f}\")\n",
    "    # if i == 3:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8ac5ee7dbd3222b9a621db727279133c0b9b65990c5851472ddfcb34807bcee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('eddl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
