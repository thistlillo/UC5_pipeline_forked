{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from posixpath import join\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecvl_yaml(name, description, filenames, labels, train_ids, valid_ids, test_ids):\n",
    "    d = {\n",
    "        \"name\"        : name,\n",
    "        \"description\" : description,\n",
    "        \"classes\"     : [], \n",
    "        \"images\"      : [],\n",
    "        \"split\"       : dict(training = train_ids, \n",
    "                            validation = valid_ids, \n",
    "                            test=test_ids)\n",
    "    }\n",
    "    imgs = []\n",
    "    for fn, l in zip(filenames, labels):\n",
    "        imgs.append({\n",
    "            \"location\": fn,\n",
    "            \"label\": l\n",
    "        })\n",
    "    d[\"images\"] = imgs\n",
    "    d[\"classes\"] = sorted(list(set(labels)))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mimic normal vs rest, unbalanced\n",
    "# 3 models, dataset stays the same, random seed changes\n",
    "\n",
    "in_file = join(\"/mnt/datasets/mimic-cxr/training_data/mimic\", \"normal_bin_unbal.tsv\")  # input dataset\n",
    "exp_fld = \"/mnt/datasets/uc5/UC5_pipeline_forked/experiments_eddl/mimic/normal_unbal\"  # output fld\n",
    "\n",
    "img_fld = \"/mnt/datasets/mimic-cxr/mimic-cxr-jpg/physionet.org/files/mimic-cxr-jpg/2.0.0\"\n",
    "\n",
    "dataset = pd.read_csv(in_file, sep=\"\\t\")\n",
    "def adjust_path(path):\n",
    "    path = path[:-len(\".dcm\")]\n",
    "    path = join(img_fld, path + \".jpg\")\n",
    "    return path\n",
    "display(dataset.T)\n",
    "\n",
    "dataset[\"path\"] = dataset[\"path\"].apply(lambda path: adjust_path(path))\n",
    "dataset.set_index(pd.RangeIndex(len(dataset)), inplace=True)\n",
    "splits = [\"train\", \"validate\", \"test\"]\n",
    "filenames = []\n",
    "labels = []\n",
    "ids = {}\n",
    "for s in splits:\n",
    "    split = dataset.loc[dataset.split == s]\n",
    "    print(f\"{s}: {split.shape}\")\n",
    "    filenames += split.path.tolist()\n",
    "    labels += split.target.tolist()\n",
    "    ids[s] = split.index.values.tolist()\n",
    "print(f\"filenames, {len(filenames)}\")\n",
    "print(f\"labels, {len(labels)}\")\n",
    "\n",
    "yml_ds = ecvl_yaml(filenames, labels, ids[\"train\"], ids[\"validate\"], ids[\"test\"])\n",
    "for k, v in yml_ds.items():\n",
    "    print(f\"{k}: {len(v)}\")\n",
    "\n",
    "n_folds = 3\n",
    "for i in range(n_folds):\n",
    "    out_fld = join(  exp_fld, f\"fold_{i}\" )\n",
    "    os.makedirs(out_fld, exist_ok=True)\n",
    "    fn = join(out_fld, \"dataset.yml\")\n",
    "    \n",
    "    with open(fn, \"w\") as fout:\n",
    "        yaml.safe_dump(yml_ds, fout, default_flow_style=None)\n",
    "    print(f\"saved {fn}\")\n",
    "#     # takes up to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"ciao\"\n",
    "a[:-(len(\"ao\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a57137f93f0d61eae732885aa4fba713e2d48086d00768a4ca093bbaf75cba17"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('eddl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
