{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import count_nonzero as nnz\n",
    "import pandas as pd\n",
    "from posixpath import join\n",
    "\n",
    "base_fld = \"/mnt/datasets/mimic-cxr/chestx-ray8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "datae = pd.read_csv( join(base_fld, \"Data_Entry_2017_v2020.csv\"))\n",
    "print(\"Data_Entry_2017_v2020.csv, shape:\", datae.shape)\n",
    "print(datae.columns)\n",
    "\n",
    "lab_col = datae.loc[:, \"Finding Labels\"].value_counts()\n",
    "print(\"unique combos:\", len(lab_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set()\n",
    "datae.loc[:, \"Finding Labels\"].apply(lambda x: labels.update([y for y in x.split(\"|\")]))\n",
    "labels.remove(\"No Finding\")\n",
    "labels = [\"No Finding\"] + sorted(labels)\n",
    "print(f\"unique labels ({len(labels)}):\", labels)\n",
    "\n",
    "l2i = {}\n",
    "i2l = {}\n",
    "for i, l in enumerate(labels):\n",
    "    l2i[l] = i\n",
    "    i2l[str(i)] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "encoding = np.zeros( (datae.shape[0], len(labels)), dtype=int)\n",
    "print(\"encoding: \", encoding.shape)\n",
    "for r, t in enumerate(datae.loc[:, [\"Image Index\", \"Finding Labels\"]].itertuples()):\n",
    "    # t[0] is the index\n",
    "    filenames.append(t[1])\n",
    "    labs = t[2].split(\"|\")\n",
    "    for l in labs:\n",
    "        encoding[r, l2i[l]] = 1\n",
    "\n",
    "print(len(filenames))\n",
    "print(encoding.shape)\n",
    "df = pd.DataFrame(data = encoding, columns=labels, index=pd.Series(filenames))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = df.sum(axis=0)\n",
    "print(\"label frequencies:\", frequencies)\n",
    "\n",
    "# Atelectasis, Cardiomegaly, Effusion, Infiltration, Mass, Nodule, Pneumonia and Pneumathorax\n",
    "paper_labels = [\"No Finding\"] + [\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\", \"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\"]\n",
    "\n",
    "# there is an error in the paper Pneumathorax, corrected in the labels above. the following check should pass\n",
    "for pl in paper_labels:\n",
    "    assert pl in labels\n",
    "\n",
    "rem_cols = [c for c in df.columns if c not in paper_labels]\n",
    "print(\"will be removed:\", rem_cols)\n",
    "\n",
    "df2 = df.drop(columns=rem_cols)\n",
    "print(\"new shape of dataset:\", df2.shape)\n",
    "\n",
    "# some images may now have 0 labels: remove them\n",
    "n_labels = df2.loc[:, paper_labels].sum(axis=1)\n",
    "with_zero_labels = n_labels == 0\n",
    "print(f\"{nnz(with_zero_labels)} images without labels... will be removed <=NO: associated with No Finding\")\n",
    "\n",
    "# ! important, see note in next code cell\n",
    "# df3 = df2.drop(df2.loc[with_zero_labels].index)\n",
    "df2.loc[with_zero_labels, \"No Finding\"] = 1\n",
    "\n",
    "#assert df2.shape[0] - df3.shape[0] == nnz(with_zero_labels)\n",
    "assert df2.shape[1] == len(paper_labels)\n",
    "\n",
    "frequencies = df2.sum(axis=0)\n",
    "n_labels = df2.sum(axis=1)\n",
    "assert nnz(n_labels == 0) == 0\n",
    "assert n_labels.sum() == df2.sum().sum()\n",
    "\n",
    "ds = df2\n",
    "del df, df2, \n",
    "\n",
    "print(f\"dataset ds, final shape: {ds.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train_val_list and test_list\n",
    "# 1. image exists in folder?\n",
    "# 2. image exists in dataset?\n",
    "def read_list(fn):\n",
    "    with open( fn, \"r\") as fin:\n",
    "        ids = fin.readlines()\n",
    "    return ids\n",
    "\n",
    "train_val = [s.strip() for s in read_list( join(base_fld, \"train_val_list.txt\") )]\n",
    "test = [s.strip() for s in read_list(join (join(base_fld, \"test_list.txt\")))]\n",
    "\n",
    "print(f\"train&validation: {len(train_val)}\")\n",
    "print(f\"test: {len(test)}\")\n",
    "print(f\"total: {len(train_val)+len(test)}\")\n",
    "assert len(train_val) + len(test) == ds.shape[0]\n",
    "# NOTE: it seems that the authos kept also the images with 0 labels after\n",
    "# selected the labels in paper_labels. From the paper, it looks like\n",
    "# they were encoded as all zeros, i.e., in the \"No Finding\" class.\n",
    "\n",
    "#import os\n",
    "#for r in ds.iterrows():\n",
    "#    fn = r[0]\n",
    "#    assert os.path.exists( join(base_fld, \"images\", fn) )\n",
    "# DONE: all images exists\n",
    "# \n",
    "ds[\"split\"] = None\n",
    "ds.loc[train_val, \"split\"] = \"train\"\n",
    "ds.loc[test, \"split\"] = \"test\"\n",
    "\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study frequencies\n",
    "\n",
    "cols = [c for c in ds.columns if c != \"split\"]\n",
    "print(cols)\n",
    "train_ds = ds.loc[ds.split == \"train\", cols]\n",
    "test_ds  = ds.loc[ds.split == \"test\", cols]\n",
    "\n",
    "train_freqs = train_ds.sum(axis=0).to_numpy()\n",
    "test_freqs = test_ds.sum(axis=0)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "\n",
    "_ = ax.bar(cols, train_freqs)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "_ = ax.bar(cols, test_freqs, alpha=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.index.name = \"filename\"\n",
    "test_ds.index.name = \"filename\"\n",
    "train_ds.to_csv( join(base_fld, \"train_set.csv\"))\n",
    "test_ds.to_csv( join(base_fld, \"test_set.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pd.read_csv( join(base_fld, \"train_set.csv\"), index_col=\"filename\")\n",
    "test_ds = pd.read_csv( join(base_fld, \"test_set.csv\"), index_col=\"filename\")\n",
    "cols = train_ds.columns.to_numpy()\n",
    "\n",
    "def labels_to_str(row):\n",
    "    e = row.to_numpy().astype(bool)\n",
    "    return \";\".join(cols[e])\n",
    "\n",
    "train_ds[\"labels\"] = train_ds.apply(lambda row: labels_to_str(row), axis=1)\n",
    "label_counts = train_ds[\"labels\"].value_counts()\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check view position\n",
    "display(datae)\n",
    "datae.loc[:, \"View Position\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8ac5ee7dbd3222b9a621db727279133c0b9b65990c5851472ddfcb34807bcee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('eddl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
